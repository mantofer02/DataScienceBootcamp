{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyUvAxOzdgMc"
   },
   "source": [
    "# Matemática para Ciencia de los Datos\n",
    "- Documento base:  https://nbviewer.jupyter.org/github/buruzaemon/svd/blob/master/01_SVD_visualizing_data.ipynb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cgawCmWJBdt"
   },
   "source": [
    "# Singular Value Descomposition (SVD)\n",
    "\n",
    "Singular value decomposition factoriza una matriz $X \\in \\mathbb{R}^{m \\times n}$  en:\n",
    "\n",
    "* Matriz $U \\in \\mathbb{R}^{m \\times m}$ son los vectores singular-izquierdos de $X$, donde las columnas son el conjunto de auto-vectores ortonormales de  $X \\, X^{T}$.\n",
    "* Matriz diagonal $\\Sigma$ con entradas $\\sigma \\in \\mathbb{R}$ que son los valores singulares  no-negativos de $X$.\n",
    "* Matriz $V \\in \\mathbb{R}^{n \\times n}$ son los vectores singular-derechos de $X$, donde las columnas son el conjunto de auto-vectores ortonormales de  $X^{T} \\, X$.\n",
    "\n",
    "tal que, \n",
    "\n",
    "\\begin{align}\n",
    "  X &= U \\, \\Sigma \\, V^{T}\n",
    "\\end{align}\n",
    "\n",
    "Las dimensiones de cada una de las matrices que factorizan $X \\in \\mathbb{R}^{m \\times n}$ son:\n",
    "\n",
    "![](https://drive.google.com/uc?id=1sVuy8_b_P9hZJF9zsrpB3j6d0EithUtR)\n",
    "\n",
    "\n",
    "Con respecto a la relación con los auto-valores y auto-vectores: \n",
    "\n",
    "* $U$ corresponde a los auto-vectores de $X \\, X^{T}$\n",
    "* $V$ corresponde a los auto-vectores de $X^{T} \\, X$\n",
    "* $\\Sigma$ corresponde a los auto-valores de $X \\, X^{T}$ o $X^{T} \\, X$, que son los mismos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Conjunto de datos Iris\n",
    "\n",
    "[Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). \n",
    "\n",
    "Los datos son multivariados, con 150 mediciones de 4 atributos (length and width cm de ambos:  sepal and petal) en tres distintas especies de Iris. De las 150 mediciones, hay 50 mediciones para _Iris setosa_, _Iris versicolor_, e _Iris virginica_.\n",
    "\n",
    "[Scikit Learn's `datasets`](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) incluye el conjunto de datos Iris.\n",
    "\n",
    "![](https://drive.google.com/uc?id=125KRc9v-vQ5dVfO2IR7jkqyRChoDtCHI)\n",
    "\n",
    "Fuente: https://www.researchgate.net/publication/265877256_How_plants_grow_and_move/figures?lo=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sklearn.datasets.load_iris()\n",
    "\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "X_zscaled = (X - X.mean()) / X.std(ddof=1)\n",
    "\n",
    "Y = pd.DataFrame(iris.target, columns=['target'])\n",
    "Y['species'] = Y.apply(lambda r: iris.target_names[r])\n",
    "\n",
    "print(\"Dimensiones de la matriz: (filas,columnas)\", X.shape)\n",
    "print(X.head(5))\n",
    "print(X_zscaled )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_iris, S_iris, Vt_iris = np.linalg.svd(X_zscaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $U$: vectores singular-izquierdos de $X$\n",
    "\n",
    "Las filas de $U$ corresponden a las filas de la matriz original de datos $X$, mientras que las columnas son el conjunto de auto-vectores ordenados, ortonormales de  $X \\, X^{T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La matriz U tiene {} filas, {} columnas\\n'.format(*U_iris.shape))\n",
    "\n",
    "print('{}'.format(pd.DataFrame(U_iris).head(5)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $V$: vectores sigular-derechos de $X$\n",
    "\n",
    "[`numpy.linalg.svd`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) retorna  $V^{T}$ en lugar de $V$, tal que las columnas de $V^{T}$ corresponden a la matriz orginal de datos de $X$. Y donde las filas son el conjunto de auto-vectores ordenados, ortonormales de $X^{T} \\, X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La matriz Vt tiene {} filas, {} columnas\\n'.format(*Vt_iris.shape))\n",
    "\n",
    "print('{}'.format(pd.DataFrame(Vt_iris).head()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\Sigma$: valores singulares de $X$\n",
    "\n",
    "Los elementos $\\sigma_{i}$ de la matriz diagonal $\\Sigma$ son los valores sigulares  no-negativos de la matriz $X$, los cuales son realmente las raíces cuadradas de los auto-valores no-zero de $X^{T} \\, X$ (y también para $X \\, X^{T}$). Estos valores singulares pueden ser usados para determinar la cantidad de varianza $X^{\\prime}$ explicada de la matriz de datos original $X$ cuando reducimos las dimensiones para encontrar una aproximación de rango inferior.\n",
    "\n",
    "\\begin{align}\n",
    "   X^{\\prime}_{k} &=  U_{k} \\, \\Sigma_{k} \\, V^{T}_{k} \\\\\n",
    "                           &\\approx X_{r} & \\text{ donde } rank(X^{\\prime}) = k \\lt rank(X) = r\n",
    "\\end{align}\n",
    "\n",
    "La cantidad de varianza que la aproximación del rango reducido  $X^{\\prime}_{k}$ explica de  $X_{r}$ es:\n",
    "\n",
    "\\begin{align}\n",
    "  \\text{suma de varianza explicada} &= \\frac{\\sum_{j=1}^{k} \\sigma_{j}^{2}}{\\sum_{i=1}^{r} \\sigma_{i}^{2}}\n",
    "\\end{align}\n",
    "\n",
    "**NOTE**: [`numpy.linalg.svd`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) realmente retorna un $\\Sigma$ que no es una matriz diagonal, sino una lista de las entradas de la diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vector Sigma tiene: \", len(S_iris), \" elementos\")\n",
    "print(S_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sv_iris = np.arange(1, S_iris.size+1)\n",
    "\n",
    "cum_var_explained_iris = [np.sum(np.square(S_iris[0:n])) / np.sum(np.square(S_iris)) for n in num_sv_iris]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se grafica la suma de la varianza explicada como una función del número de valores singulares usados cuando reducimos el rango para encontrar una matriz de rango-inferior $X^{\\prime}$ para aproximar $X$. Lo cual da pistas de cuántas dimensiones se podrían usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.0,5.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(num_sv_iris,\n",
    "         cum_var_explained_iris,\n",
    "         color='#2171b5',\n",
    "         label='varianza explicada',\n",
    "         alpha=0.65,\n",
    "         zorder=1000)\n",
    "\n",
    "plt.scatter(num_sv_iris,\n",
    "            sklearn.preprocessing.normalize(S_iris.reshape((1,-1))),\n",
    "            color='#fc4e2a',\n",
    "            label='valores singulares (normalizados)',\n",
    "            alpha=0.65,\n",
    "            zorder=1000)\n",
    "\n",
    "plt.legend(loc='center right', scatterpoints=1, fontsize=8)\n",
    "\n",
    "ax.set_xticks(num_sv_iris)\n",
    "ax.set_xlim(0.8, 4.1)\n",
    "ax.set_ylim(0.0, 1.1)\n",
    "ax.set_xlabel(r'Número de valores singulares utilizados')\n",
    "ax.set_ylabel('Varianza en los datos explicada')\n",
    "ax.set_title('Conjunto de datos Iris: suma de la varianza explicada & valores singulares',\n",
    "             fontsize=14,\n",
    "             y=1.03)\n",
    "\n",
    "ax.set_facecolor('0.98')\n",
    "\n",
    "plt.grid(alpha=0.8, zorder=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducción de dimensión\n",
    "\n",
    "A juzgar por la curva que representa la suma de la varianza explicada en la figura anterior, se puede ver que:\n",
    "\n",
    "* con 2 valores singulares, cerca de 96.5% de la varianza de $X$ puede ser explicada\n",
    "* con 3 valores singulares, ese número llega hasta aproximadamente 99.8%\n",
    "\n",
    "Ahora se grafica utilizando los primeros 2 valores singulares para representar los datos en los ejes $x$ y $y$, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_setosa = np.where(iris.target==0)[0]\n",
    "idx_versicolor = np.where(iris.target==1)[0]\n",
    "idx_virginica = np.where(iris.target==2)[0]\n",
    "\n",
    "setosa_x = U_iris[idx_setosa, 0]\n",
    "setosa_y = U_iris[idx_setosa, 1]\n",
    "\n",
    "versicolor_x = U_iris[idx_versicolor, 0]\n",
    "versicolor_y = U_iris[idx_versicolor, 1]\n",
    "\n",
    "virginica_x = U_iris[idx_virginica, 0]\n",
    "virginica_y = U_iris[idx_virginica, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.0,5.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.scatter(setosa_x,\n",
    "            setosa_y,\n",
    "            marker='o',\n",
    "            color='#66c2a5',\n",
    "            label='Iris-setosa',\n",
    "            zorder=1000)\n",
    "\n",
    "plt.scatter(versicolor_x,\n",
    "            versicolor_y,\n",
    "            marker='D',\n",
    "            color='#fc8d62',\n",
    "            label='Iris-versicolor',\n",
    "            zorder=1000)\n",
    "\n",
    "plt.scatter(virginica_x,\n",
    "            virginica_y,\n",
    "            marker='^',\n",
    "            color='#8da0cb',\n",
    "            label='Iris-virginica',\n",
    "            zorder=1000)\n",
    "\n",
    "plt.legend(loc='upper left', scatterpoints=1, fontsize=8)\n",
    "\n",
    "ax.set_xlabel(r'valor singular $\\sigma_{1}$')\n",
    "ax.set_ylabel(r'valor singular $\\sigma_{2}$')\n",
    "ax.set_title('Gráfico 2D del conjunto de datos Iris',\n",
    "             fontsize=14,\n",
    "             y=1.03)\n",
    "ax.set_facecolor('0.98')\n",
    "\n",
    "plt.grid(alpha=0.6, zorder=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación final:**\n",
    "\n",
    "Se logra visualizar el conjunto de datos original que estaba en 4D en 2D usando las primeras dos columnas de valores singulares de $U$, matriz de vectores singular-izquierda, se logra ver que hay una clara separación para las clases _Iris setosa_ y las otras. De otra manera, la diferenciación entre _Iris versicolor_ e _Iris virginica_ no parece clara.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo adicional en imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "img = Image.open('perritaejemplo.jpg')\n",
    "print(\"Detalles de img: \", img)\n",
    "# convert image to grayscale\n",
    "imggray = img.convert('LA')\n",
    "print(\"Detalles de imggray: \", imggray)\n",
    "print(imggray)\n",
    "\n",
    "# convert to numpy array\n",
    "imgmat = np.array(list(imggray.getdata(band=0)), float)\n",
    "\n",
    "# Reshape according to orginal image dimensions\n",
    "imgmat.shape = (imggray.size[1], imggray.size[0])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Resolución de la imagen original: \", imgmat.shape)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(imgmat, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "U, D, V = np.linalg.svd(imgmat)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Dimensiones de U:\", U.shape)\n",
    "print(\"Dimensiones de D:\", D.shape)\n",
    "print(\"Dimensiones de V:\", V.shape)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for i in [5, 50, 200, 500, 1500, 2000]:\n",
    "    #reconstimg = np.matrix(U[:, :i]) * np.diag(D[:i]) * np.matrix(V[:i, :])\n",
    "    reconstimg = np.matmul( np.matmul( np.matrix(U[:, :i]) , np.diag(D[:i]) ) , np.matrix(V[:i, :]) )\n",
    "    \n",
    "    plt.imshow(reconstimg, cmap='gray')\n",
    "    title = \"n = %s\" % i\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_LACV_DeterminanteyAutoVectores.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
