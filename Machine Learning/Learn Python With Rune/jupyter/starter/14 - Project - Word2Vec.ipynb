{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b13b1e",
   "metadata": {},
   "source": [
    "# Project: Create a Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b981a3",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41729b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a98c3250",
   "metadata": {},
   "source": [
    "### Step 2: Download stopwords\n",
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374bc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9012c520",
   "metadata": {},
   "source": [
    "### Step 3: Read content and sentinize\n",
    "- Initialize an empty list called **all_sentences**\n",
    "- For each filename in **'files/holmes'**:\n",
    "    - HINT: Use **os.listdir(...)** ([docs](https://docs.python.org/3/library/os.html#os.listdir))\n",
    "- Open the file and read the content and convert to lowercase and apply **nltk.sent_tokenize** on content.\n",
    "    - Use **lower()** on content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b468e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80be94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e4362c",
   "metadata": {},
   "source": [
    "### Step 4: Tokenize each sentence\n",
    "- Get all words by applying **nltk.word_tokenize** on them and assign the result to **all_words**\n",
    "    - HINT: Use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c19b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98050e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "959014e8",
   "metadata": {},
   "source": [
    "### Step 5: Remove all stop words\n",
    "- Use **stopwords.words('english')** to filter all the words in **all_words**\n",
    "    - HINT: iterate over the length of **all_words**, for each index use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f413a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b4003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40656352",
   "metadata": {},
   "source": [
    "### Step 6: Remove special characters\n",
    "- Iterate over items in **all_words** to remove words with special characters\n",
    "    - HINT: Use **isalpha()** ([doc](https://docs.python.org/3/library/stdtypes.html#str.isalpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a4d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c12fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8bca8cf",
   "metadata": {},
   "source": [
    "### Step 7: Install gensim and python-Levenshtein\n",
    "- Run the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32c928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e71dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e16a94c5",
   "metadata": {},
   "source": [
    "### Step 8: Import another library\n",
    "- Run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6672e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6dad3d2",
   "metadata": {},
   "source": [
    "### Step 9: Create a model\n",
    "- Use **Word2Vec** on **all_words**\n",
    "    - Use **min_count=2** : Ignores all words with total frequency lower than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64583d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb2567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1da22183",
   "metadata": {},
   "source": [
    "### Step 10: Find distances\n",
    "- Try to run **model.wv.distance('holmes', 'watson')**\n",
    "- Try to run **model.wv.distance('holmes', 'water')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f4903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31650834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b26dd8c",
   "metadata": {},
   "source": [
    "### Step 11: Find closests words\n",
    "- Get all the words\n",
    "    - HINT: **words = model.wv.index_to_key**\n",
    "- Implement a function **closets_words(word)**\n",
    "    - HINT: **distances = {w: model.wv.distance(word, w) for w in words}**\n",
    "    - HINT: **sorted(distances, key=lambda w: distances[w])[:15]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb370b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c2b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f03bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
