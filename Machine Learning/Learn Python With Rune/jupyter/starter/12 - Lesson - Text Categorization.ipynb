{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679b5aa5",
   "metadata": {},
   "source": [
    "# Text Categorization\n",
    "### Goal of lesson\n",
    "- What is Text Categorization\n",
    "- Learn about the Bag-of-Words Model\n",
    "- Understand Naive Bayes' Rule\n",
    "- How to use Naive Bayes' Rule for sentiment classification (text categorization)\n",
    "- What problem smoothing solves\n",
    "\n",
    "### What is Text Categorization\n",
    "- Example:\n",
    "    - Inbox vs Spam\n",
    "    - Product review: Positive vs Negtive review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b433d",
   "metadata": {},
   "source": [
    "### Bag-of-Words Model\n",
    "- Model that represents text as an unordered collection of words\n",
    "- The structure is not important\n",
    "- Works well to classify\n",
    "\n",
    "- Example\n",
    "    - I **love** this product.\n",
    "    - This product feels **cheap**.\n",
    "    - This is the **best** product ever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280b34e",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "- Naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naÃ¯ve) independence assumptions between the features ([wiki](https://en.wikipedia.org/wiki/Naive_Bayes_classifier))\n",
    "\n",
    "### Bayes' Rule Theorem \n",
    "- Describes the probability of an event, based on prior knowledge of conditions that might be related to the event ([wiki](https://en.wikipedia.org/wiki/Bayes%27_theorem))\n",
    "- $P(b|a) = \\frac{P(a|b)P(b)}{P(a)}$\n",
    "\n",
    "### Explained\n",
    "$P(\\text{positive})$\n",
    "\n",
    "$P(\\text{positive}| \\text{\"I love this product\"}) = P(\\text{positive} | \\text{\"I\", \"love\", \"this\", \"product\"})$\n",
    "\n",
    "Bayes's Rule implies it is equal to\n",
    "\n",
    "$\\frac{P(\\text{\"I\", \"love\", \"this\", \"product\"} | \\text{positive}) P(\\text{positive})}{P(\\text{\"I\", \"love\", \"this\", \"product\"})}$ \n",
    "\n",
    "Or proportional to\n",
    "\n",
    "$P(\\text{\"I\", \"love\", \"this\", \"product\"} | \\text{positive}) P(\\text{positive})$\n",
    "\n",
    "The 'Naive' part we use this to simplify\n",
    "\n",
    "$P(\\text{positive})P(\\text{\"I\"} | \\text{positive})P(\\text{\"love\"} | \\text{positive})P(\\text{\"this\"} | \\text{positive})P(\\text{\"product\"} | \\text{positive})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0418e",
   "metadata": {},
   "source": [
    "$P(\\text{positive})=\\frac{\\text{number of positive samples}}{\\text{number of samples}}$\n",
    "\n",
    "$P(\\text{\"love\"}|\\text{positive})=\\frac{\\text{number of positive samples with \"love\"}}{\\text{number of positive samples}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fef7a3",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "\"I love this product\"\n",
    "\n",
    "| positive | negative |\n",
    "| ------ | ------ |\n",
    "| 0.47 | 0.53 |\n",
    "\n",
    "| word | positive | negative |\n",
    "| ------ | ------ | ------ |\n",
    "| \"I\" | 0.30 | 0.20 |\n",
    "| \"love\" | 0.40 | 0.05 |\n",
    "| \"this\" | 0.28 | 0.42 |\n",
    "| \"product\" | 0.25 | 0.28 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272bf3bd",
   "metadata": {},
   "source": [
    "$P(\\text{positive})P(\\text{\"I\"} | \\text{positive})P(\\text{\"love\"} | \\text{positive})P(\\text{\"this\"} | \\text{positive})P(\\text{\"product\"} | \\text{positive}) = 0.47 * 0.30 * 0.40 * 0.28 * 0.25 = 0.003948$\n",
    "\n",
    "$P(\\text{negative})P(\\text{\"I\"} | \\text{negative})P(\\text{\"love\"} | \\text{negative})P(\\text{\"this\"} | \\text{negative})P(\\text{\"product\"} | \\text{negative}) = 0.53 * 0.20 * 0.05 * 0.42 * 0.28 = 0.00062328$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2ff37",
   "metadata": {},
   "source": [
    "Calculate the likelyhood\n",
    "\n",
    "\"I love this product\" is positive: 0.00394 / (0.00394 + 0.00062328) = 86.3%\n",
    "\n",
    "\"I love this product\" is negative: 0.00062328 / (0.00394 + 0.00062328) = 13.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9466a9",
   "metadata": {},
   "source": [
    "### Problem\n",
    "- If a word never showed up in a sentence\n",
    "\n",
    "### Additive Smoothing\n",
    "- Adding a value to each value in the distribution to smooth the data\n",
    "\n",
    "### Laplace smoothing\n",
    "- Adding 1 to each value in the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d280e6",
   "metadata": {},
   "source": [
    "> #### Programming Notes:\n",
    "> - Libraries used\n",
    ">     - [**pandas**](https://pandas.pydata.org) - a data analysis and manipulation tool\n",
    ">     - [**nltk**](https://www.nltk.org) - Natural Language Toolkit\n",
    "> - Functionality and concepts used\n",
    ">     - [**CSV**](https://en.wikipedia.org/wiki/Comma-separated_values) file ([Lecture on CSV](https://youtu.be/LEyojSOg4EI))\n",
    ">     - [**read_csv()**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) read a comma-separated values (csv) file into **pandas** DataFrame.\n",
    ">     - **List/Set/Dict Comprehension** to convert data ([Lecture on **List Comprehension**](https://youtu.be/vCYEvtfXdig))\n",
    ">     - [**word_tokenize**](https://www.nltk.org/api/nltk.tokenize.html) Tokenize a string to split off punctuation other than periods\n",
    ">     - [**NaiveBayesClassifier**](https://www.nltk.org/_modules/nltk/classify/naivebayes.html) A classifier based on the Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf53be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baac40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36629cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a8097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612306aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac46fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca25b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f621c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
